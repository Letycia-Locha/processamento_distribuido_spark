# ğŸš€ CVM Data Pipeline: Uma Jornada em Big Data com PySpark

## ğŸ“Œ VisÃ£o Geral do Projeto

Este projeto foi desenvolvido como um estudo prÃ¡tico e intensivo sobre Engenharia de Dados e Analytics utilizando dados reais da ComissÃ£o de Valores MobiliÃ¡rios (CVM) referentes a janeiro de 2024.

O objetivo foi construir um pipeline completo seguindo a Arquitetura Medallion, saindo do dado bruto atÃ© a geraÃ§Ã£o de insights estratÃ©gicos de mercado.

---

## ğŸ—ï¸ Arquitetura do Pipeline (Medallion)

O projeto estÃ¡ organizado em trÃªs camadas lÃ³gicas, cada uma com uma responsabilidade clara:

### ğŸŸ« Camada Bronze (Raw)

IngestÃ£o dos dados brutos em formato `.csv`, extraÃ­dos via API e convertidos para **Parquet com compressÃ£o Snappy**, garantindo melhor desempenho e otimizaÃ§Ã£o de armazenamento.

### â¬œ Camada Silver (Cleansing)

Fase de higienizaÃ§Ã£o dos dados.
Foram identificados **567.834 valores nulos** na coluna `ID_SUBCLASSE`.

Optou-se pela preservaÃ§Ã£o dos valores `NULL` para assegurar que as agregaÃ§Ãµes de negÃ³cio permanecessem tecnicamente precisas e nÃ£o enviesassem anÃ¡lises financeiras.

### ğŸŸ¨ Camada Gold (Analytics)

CriaÃ§Ã£o de tabelas analÃ­ticas voltadas para consumo e geraÃ§Ã£o de insights estratÃ©gicos, como:

* ğŸ“ˆ Market Share
* ğŸ“Š Volatilidade

A volatilidade foi calculada a partir do desvio padrÃ£o do patrimÃ´nio lÃ­quido:

$$
\sigma = \sqrt{\frac{1}{N - 1} \sum_{i=1}^{N} \left(x_i - \bar{x}\right)^2}
$$

---

## ğŸ§  Principais Aprendizados

Este projeto nÃ£o foi apenas sobre cÃ³digo, mas principalmente sobre **tomada de decisÃ£o arquitetural**.

**Processamento DistribuÃ­do:**
CompreensÃ£o prÃ¡tica de como o Spark distribui tarefas entre mÃºltiplos nÃºcleos para processar milhÃµes de linhas em segundos.

**Qualidade de Dados vs. Regra de NegÃ³cio:**
Discernimento entre quando preencher valores nulos na camada Silver e quando preservÃ¡-los para evitar distorÃ§Ãµes analÃ­ticas na camada Gold.

**SeguranÃ§a e DevSecOps:**
ImplementaÃ§Ã£o de boas prÃ¡ticas com uso de GitHub Secrets e tokens para upload de dados via Google Colab, garantindo que credenciais sensÃ­veis nÃ£o fossem expostas no cÃ³digo.

**Git Flow Profissional:**
Trabalho com branches (`camada-medallion`) no GitHub, assegurando que a branch `main` permanecesse estÃ¡vel enquanto novas funcionalidades eram desenvolvidas.

---

## ğŸ› ï¸ Tecnologias e Ferramentas

* **Linguagem:** Python
* **Framework de Big Data:** PySpark
* **Armazenamento:** Apache Parquet (Snappy Compression)
* **Ambiente de Nuvem:** Google Colab & Google Drive
* **VisualizaÃ§Ã£o:** Plotly Express
* **Versionamento:** Git & GitHub (Secrets & Branching)

---

## ğŸ“Š Insights ExtraÃ­dos (Jan/2024)

**Fluxo de Capital:**
O mÃªs de janeiro apresentou um saldo lÃ­quido positivo de **R$ 109 bilhÃµes**, indicando um forte movimento de entrada na indÃºstria de fundos.

**ConcentraÃ§Ã£o de Risco:**
A classe FI (Fundo de Investimento) demonstrou domÃ­nio no mercado, enquanto classes como FAPI apresentaram maior sensibilidade a resgates no inÃ­cio do ano.

---

## ğŸ‘¤ Autora

**Letycia Locha**
Engenheira de Dados em ConstruÃ§Ã£o

ğŸ”— Meu GitHub
